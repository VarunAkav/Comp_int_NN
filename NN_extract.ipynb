{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import model_from_json\n",
    "import json\n",
    "import os\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the models from the Models folder will be stored in a dictionary\n",
    "models_json_str = dict()\n",
    "for filepath in os.listdir('Models'):\n",
    "    with open(os.path.join('Models',filepath),'r') as model_file:\n",
    "        filename, ext = os.path.splitext(filepath)\n",
    "        if ext == '.json':\n",
    "            models_json_str[filename] = model_file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Special Layers\n",
    "MPOOL_LAYERS = ['MaxPooling1D','MaxPooling2D', 'MaxPooling3D']\n",
    "APOOL_LAYERS = ['AveragePooling1D', 'AveragePooling2D', 'AveragePooling3D']\n",
    "POOL_LAYERS = MPOOL_LAYERS + APOOL_LAYERS\n",
    "GMPOOL_LAYERS = ['GloabalMaxPooling1D','GloabalMaxPooling2D', 'GloabalMaxPooling3D']\n",
    "GAPOOL_LAYERS = ['GlobalAveragePooling1D', 'GlobalAveragePooling2D', 'GlobalAveragePooling3D']\n",
    "GPOOL_LAYERS = GMPOOL_LAYERS + GAPOOL_LAYERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting Data from the JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'layers_ls': [{'class_name': 'InputLayer', 'name': 'input_1', 'shape': [28, 28, 1], 'Neuron_count': 784, 'Number of connections': None, 'Number of multiplications': 0, 'Number of additions': 0}, {'class_name': 'Conv2D', 'name': 'conv2d', 'shape': [26, 26, 32], 'Neuron_count': 21632, 'Number of connections': 194688, 'Number of multiplications': 194688, 'Number of additions': 21632}, {'class_name': 'MaxPooling2D', 'name': 'max_pooling2d', 'shape': [13, 13, 32], 'Neuron_count': 5408, 'Number of connections': 21632, 'Number of multiplications': 0, 'Number of comparisions': 3}, {'class_name': 'Conv2D', 'name': 'conv2d_1', 'shape': [11, 11, 64], 'Neuron_count': 7744, 'Number of connections': 2230272, 'Number of multiplications': 2230272, 'Number of additions': 7744}, {'class_name': 'MaxPooling2D', 'name': 'max_pooling2d_1', 'shape': [5, 5, 64], 'Neuron_count': 1600, 'Number of connections': 6400, 'Number of multiplications': 0, 'Number of comparisions': 3}, {'class_name': 'Flatten', 'name': 'flatten', 'shape': [1600], 'Neuron_count': 1600, 'Number of connections': None, 'Number of multiplications': 0, 'Number of additions': 0}, {'class_name': 'Dropout', 'name': 'dropout', 'shape': [1600], 'Neuron_count': 1600, 'Number of connections': None, 'Number of multiplications': 0, 'Number of additions': 0}, {'class_name': 'Dense', 'name': 'dense', 'shape': [10], 'Neuron_count': 10, 'Number of connections': 16000, 'Number of multiplications': 16000, 'Number of additions': 10}], 'layers_count': 8, 'Total_neuron_count': 40378, 'Total number of connections': 2468992, 'Total number of multiplications': 2440960, 'Total number of additions': 29386, 'Total number of comparisions': 6}\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "class Model_Extractor:\n",
    "    MPOOL_LAYERS = ['MaxPooling1D','MaxPooling2D', 'MaxPooling3D']\n",
    "    APOOL_LAYERS = ['AveragePooling1D', 'AveragePooling2D', 'AveragePooling3D']\n",
    "    POOL_LAYERS = MPOOL_LAYERS + APOOL_LAYERS\n",
    "    GMPOOL_LAYERS = ['GloabalMaxPooling1D','GloabalMaxPooling2D', 'GloabalMaxPooling3D']\n",
    "    GAPOOL_LAYERS = ['GlobalAveragePooling1D', 'GlobalAveragePooling2D', 'GlobalAveragePooling3D']\n",
    "    GPOOL_LAYERS = GMPOOL_LAYERS + GAPOOL_LAYERS\n",
    "\n",
    "    def __init__(self, model_json_str):\n",
    "        self.model = model_from_json(model_json_str)\n",
    "        self.model_json = json.loads(model_json_str)\n",
    "        self.config = self.model_json['config']\n",
    "        # self.target_layer_models = dict()\n",
    "        self.outputs = dict()\n",
    "\n",
    "        self.make_target_layer_models()\n",
    "        \n",
    "        self.get_output()\n",
    "        self.dump_output('output.json')\n",
    "        \n",
    "        \n",
    "    def get_layers(self):\n",
    "        self.outputs['layers_ls'] = []\n",
    "        for layer in self.model_json['config']['layers']:\n",
    "            self.outputs['layers_ls'].append({'class_name': layer['class_name'],'name': layer['config']['name']})\n",
    "        \n",
    "        self.outputs['layers_count'] = len(self.outputs['layers_ls'])\n",
    "    \n",
    "    def get_layer_shape(self):\n",
    "        self.outputs['layers_ls'][0]['shape'] = self.config['layers'][0]['config']['batch_input_shape'][1:]\n",
    "        for layer in self.outputs['layers_ls'][1:]:\n",
    "            layer['shape'] = [*self.model.get_layer(layer['name']).output_shape[1:]]\n",
    "\n",
    "    def get_neurons(self):\n",
    "        total_neuron_count = 0\n",
    "        for layer in self.outputs['layers_ls']:\n",
    "            layer['Neuron_count'] = reduce(lambda x,y : x*y, layer['shape'])\n",
    "            total_neuron_count += layer['Neuron_count']\n",
    "        \n",
    "        self.outputs['Total_neuron_count'] = total_neuron_count\n",
    "\n",
    "    def make_model_of_layer(self,target_layer_json: json):\n",
    "        input_shape = [*self.model.get_layer(target_layer_json['config']['name']).input_shape]\n",
    "        layer_model_json = deepcopy(self.model_json)\n",
    "        layer_model_json['config']['layers'][0]['config']['batch_input_shape'] = input_shape\n",
    "\n",
    "        for layer in self.model_json['config']['layers'][1:]:\n",
    "            if layer == target_layer_json:\n",
    "                continue\n",
    "            layer_model_json['config']['layers'].remove(layer)\n",
    "        \n",
    "        if \"activation\" in layer_model_json['config']['layers'][1]['config']:\n",
    "            layer_model_json['config']['layers'][1]['config']['activation'] = 'relu'\n",
    "\n",
    "        layer_model = model_from_json(json.dumps(layer_model_json))\n",
    "        return layer_model\n",
    "    \n",
    "    def make_target_layer_models(self):\n",
    "        target_layer_models = {}\n",
    "        for layer in self.config['layers'][1:]:\n",
    "            target_layer_models[layer['config']['name']] = self.make_model_of_layer(layer)\n",
    "        self.target_layer_models = target_layer_models\n",
    "    \n",
    "    def get_layer_connections(self,target_layer_json: json,layer_i: int):\n",
    "        # layer_model = self.make_model_of_layer(target_layer_json)\n",
    "        layer_model = self.target_layer_models[target_layer_json['config']['name']]\n",
    "        input_shape = layer_model.layers[0].input_shape\n",
    "        if layer_model.get_weights():\n",
    "            weights_shape, biases_shape = layer_model.get_weights()\n",
    "            weights_shape, biases_shape = weights_shape.shape, biases_shape.shape\n",
    "            weights = np.zeros(weights_shape) + 1\n",
    "            biases = np.zeros(biases_shape)\n",
    "            layer_model.set_weights([weights,biases])\n",
    "            extractor = tf.keras.Model(inputs=layer_model.inputs,outputs=layer_model.layers[0].output)\n",
    "\n",
    "            features = extractor(np.zeros((1, *input_shape[1:]))+1)\n",
    "            return features[0]\n",
    "        if target_layer_json['class_name'] in POOL_LAYERS:\n",
    "            pool_size = np.prod(target_layer_json['config']['pool_size'])\n",
    "            # print(pool_size)\n",
    "            no_of_neurons = self.outputs[\"layers_ls\"][layer_i][\"Neuron_count\"]\n",
    "            # print(no_of_neurons*pool_size)\n",
    "            return no_of_neurons*pool_size\n",
    "        return None\n",
    "\n",
    "    def get_connections(self):\n",
    "        # self.outputs['layers_ls'][0]['Layer connections'] = None\n",
    "        self.outputs['layers_ls'][0]['Number of connections'] = None\n",
    "        total_connections = 0\n",
    "        for layer_i, (layer, out_layer) in enumerate(zip(self.config['layers'][1:],self.outputs['layers_ls'][1:]),start=1):\n",
    "            # out_layer['Layer connections'] = self.get_layer_connections(layer)\n",
    "            out_layer['Number of connections'] = np.sum(self.get_layer_connections(layer,layer_i))\n",
    "            if out_layer['Number of connections']:\n",
    "                out_layer['Number of connections'] = int(out_layer['Number of connections'])\n",
    "                total_connections += out_layer['Number of connections']\n",
    "        self.outputs['Total number of connections'] = total_connections\n",
    "    \n",
    "    def get_layer_multiplications(self, target_layer_json: json, layer_i: int):\n",
    "        layer_model = self.target_layer_models[target_layer_json['config']['name']]\n",
    "        input_shape = layer_model.layers[0].input_shape\n",
    "        if layer_model.get_weights():\n",
    "            weights_shape, biases_shape = layer_model.get_weights()\n",
    "            weights_shape, biases_shape = weights_shape.shape, biases_shape.shape\n",
    "            weights = np.zeros(weights_shape) + 1\n",
    "            biases = np.zeros(biases_shape)\n",
    "            layer_model.set_weights([weights,biases])\n",
    "            extractor = tf.keras.Model(inputs=layer_model.inputs,outputs=layer_model.layers[0].output)\n",
    "\n",
    "            features = extractor(np.zeros((1, *input_shape[1:]))+1)\n",
    "            return int(np.sum(features[0]))\n",
    "        if target_layer_json['class_name'] in APOOL_LAYERS:\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    def get_multiplications(self):\n",
    "        self.outputs['layers_ls'][0]['Number of multiplications'] = 0\n",
    "        total_multiplications = 0\n",
    "        total_divisions = 0\n",
    "        for layer_i, (layer, out_layer) in enumerate(zip(self.config['layers'][1:],self.outputs['layers_ls'][1:]),start=1):\n",
    "            # out_layer['Layer connections'] = self.get_layer_connections(layer)\n",
    "            if layer['class_name'] in APOOL_LAYERS + GAPOOL_LAYERS:\n",
    "                # Returns number of divisions in AveragePool layers\n",
    "                out_layer['Number of divisions'] = self.get_layer_multiplications(layer,layer_i)\n",
    "                total_divisions += out_layer['Number of divisions']\n",
    "\n",
    "            else:\n",
    "                out_layer['Number of multiplications'] = self.get_layer_multiplications(layer,layer_i)\n",
    "                total_multiplications += out_layer['Number of multiplications']\n",
    "        self.outputs['Total number of multiplications'] = total_multiplications\n",
    "    \n",
    "    def get_layer_additions(self,target_layer_json: json, layer_i):\n",
    "        layer_model = self.target_layer_models[target_layer_json['config']['name']]\n",
    "        input_shape = layer_model.layers[0].input_shape\n",
    "        if layer_model.get_weights():\n",
    "            weights_shape, biases_shape = layer_model.get_weights()\n",
    "            weights_shape, biases_shape = weights_shape.shape, biases_shape.shape\n",
    "            weights = np.zeros(weights_shape)\n",
    "            biases = np.zeros(biases_shape) + 1\n",
    "            layer_model.set_weights([weights,biases])\n",
    "            extractor = tf.keras.Model(inputs=layer_model.inputs,outputs=layer_model.layers[0].output)\n",
    "\n",
    "            features = extractor(np.zeros((1, *input_shape[1:])))\n",
    "            return int(np.sum(features[0]))\n",
    "        if target_layer_json['class_name'] in POOL_LAYERS:\n",
    "            # Returns the number of additions for AveragePool layers and number of comparisions in MaxPool layers\n",
    "            pool_size = np.prod(target_layer_json['config']['pool_size'])\n",
    "            return int(pool_size-1)\n",
    "        # if target_layer_json['class_name'] in MPOOL_LAYERS:\n",
    "\n",
    "        return 0\n",
    "        \n",
    "    def get_additions(self):\n",
    "        self.outputs['layers_ls'][0]['Number of additions'] = 0\n",
    "        total_additions = 0\n",
    "        total_comparisions = 0\n",
    "        # for layer, out_layer in zip(self.config['layers'][1:],self.outputs['layers_ls'][1:]):\n",
    "        for layer_i, (layer, out_layer) in enumerate(zip(self.config['layers'][1:],self.outputs['layers_ls'][1:]),start=1):\n",
    "            # out_layer['Layer connections'] = self.get_layer_connections(layer)\n",
    "            if layer['class_name'] in MPOOL_LAYERS + GMPOOL_LAYERS:\n",
    "                # Records number of comparisions for MaxPool layers\n",
    "                out_layer['Number of comparisions'] = self.get_layer_additions(layer,layer_i)\n",
    "                total_comparisions += out_layer['Number of comparisions']\n",
    "            else:\n",
    "                # Records number of additions for AveragePool layers\n",
    "                out_layer['Number of additions'] = self.get_layer_additions(layer, layer_i)\n",
    "                total_additions += out_layer['Number of additions']\n",
    "        self.outputs['Total number of additions'] = total_additions\n",
    "        self.outputs['Total number of comparisions'] = total_comparisions\n",
    "\n",
    "    def get_output(self):\n",
    "        self.get_layers()\n",
    "        # print(self)\n",
    "        self.get_layer_shape()\n",
    "        self.get_neurons()\n",
    "        self.get_connections()\n",
    "        self.get_multiplications()\n",
    "        self.get_additions()\n",
    "\n",
    "    def dump_output(self,filename):\n",
    "        # Saves the output in a given file\n",
    "        with open(filename,'w') as output_file:\n",
    "            print(self.outputs)\n",
    "            json.dump((self.outputs),output_file,indent=4, separators=(',',' : '))\n",
    "    \n",
    "def main():\n",
    "    MNIST_convnet_extractor = Model_Extractor(models_json_str['Simple_MNIST_convnet'])\n",
    "    # print(MNIST_convnet_extractor.outputs)\n",
    "    print(MNIST_convnet_extractor.model.layers[0].dtype)\n",
    "\n",
    "        # print((MNIST_convnet_extractor.outputs))\n",
    "        # MNIST_convnet_extractor.outputs\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'layers_ls': [{'class_name': 'InputLayer',\n",
       "   'name': 'input_1',\n",
       "   'shape': [28, 28, 1],\n",
       "   'Neuron_count': 784,\n",
       "   'Number of connections': None,\n",
       "   'Number of multiplications': 0,\n",
       "   'Number of additions': 0},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'name': 'conv2d',\n",
       "   'shape': [26, 26, 32],\n",
       "   'Neuron_count': 21632,\n",
       "   'Number of connections': 194688.0,\n",
       "   'Number of multiplications': 194688.0,\n",
       "   'Number of additions': 21632.0},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'name': 'max_pooling2d',\n",
       "   'shape': [13, 13, 32],\n",
       "   'Neuron_count': 5408,\n",
       "   'Number of connections': None,\n",
       "   'Number of multiplications': 0,\n",
       "   'Number of additions': 0},\n",
       "  {'class_name': 'Conv2D',\n",
       "   'name': 'conv2d_1',\n",
       "   'shape': [11, 11, 64],\n",
       "   'Neuron_count': 7744,\n",
       "   'Number of connections': 2230272.0,\n",
       "   'Number of multiplications': 2230272.0,\n",
       "   'Number of additions': 7744.0},\n",
       "  {'class_name': 'MaxPooling2D',\n",
       "   'name': 'max_pooling2d_1',\n",
       "   'shape': [5, 5, 64],\n",
       "   'Neuron_count': 1600,\n",
       "   'Number of connections': None,\n",
       "   'Number of multiplications': 0,\n",
       "   'Number of additions': 0},\n",
       "  {'class_name': 'Flatten',\n",
       "   'name': 'flatten',\n",
       "   'shape': [1600],\n",
       "   'Neuron_count': 1600,\n",
       "   'Number of connections': None,\n",
       "   'Number of multiplications': 0,\n",
       "   'Number of additions': 0},\n",
       "  {'class_name': 'Dropout',\n",
       "   'name': 'dropout',\n",
       "   'shape': [1600],\n",
       "   'Neuron_count': 1600,\n",
       "   'Number of connections': None,\n",
       "   'Number of multiplications': 0,\n",
       "   'Number of additions': 0},\n",
       "  {'class_name': 'Dense',\n",
       "   'name': 'dense',\n",
       "   'shape': [10],\n",
       "   'Neuron_count': 10,\n",
       "   'Number of connections': 1.0,\n",
       "   'Number of multiplications': 1.0,\n",
       "   'Number of additions': 1.0}],\n",
       " 'layers_count': 8,\n",
       " 'Total_neuron_count': 40378,\n",
       " 'Total number of connections': 2424961.0,\n",
       " 'Total number of multiplications': 2424961.0,\n",
       " 'Total number of additions': 29377.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json.dumps((MNIST_convnet_extract.outputs),indent=4, separators=('',' : '))\n",
    "MNIST_convnet_extract.outputs\n",
    "# with open('output.json', 'w') as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 6\n",
      "1 2 7\n",
      "2 3 8\n",
      "3 4 9\n",
      "4 5 10\n"
     ]
    }
   ],
   "source": [
    "A = [1,2,3,4,5]\n",
    "B = [6,7,8,9,10]\n",
    "for i, (a,b) in enumerate(zip(A,B)):\n",
    "    print(i,a,b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.get_layer_connections(MNIST_convnet_extract.config['layers'][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_name': 'Dense',\n",
       " 'config': {'name': 'dense',\n",
       "  'trainable': True,\n",
       "  'dtype': 'float32',\n",
       "  'units': 10,\n",
       "  'activation': 'softmax',\n",
       "  'use_bias': True,\n",
       "  'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "   'config': {'seed': None}},\n",
       "  'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "  'kernel_regularizer': None,\n",
       "  'bias_regularizer': None,\n",
       "  'activity_regularizer': None,\n",
       "  'kernel_constraint': None,\n",
       "  'bias_constraint': None}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.config['layers'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "MNIST_convnet_extract.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.model.layers[-1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 26, 26, 32) dtype=float32 (created by layer 'conv2d')>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.model.layers[0].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 26, 26, 32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.model.layers[0].output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                16010     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,826\n",
      "Trainable params: 34,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(MNIST_convnet_extract.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.layers as klayers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "# x_input = np.zeros((28,28,1)) + 1\n",
    "input_1 = MNIST_convnet_extract.model.input\n",
    "output_1 = MNIST_convnet_extract.model.layers[0].output\n",
    "fun = K.function([input_1,K.learning_phase()],output_1)\n",
    "\n",
    "test = np.zeros((1,28,28,1)) + 1\n",
    "layer_output = fun([test,1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 28, 28, 1) dtype=float32 (created by layer 'input_1')>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST_convnet_extract.model.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]]\n",
      "[[[1 2 3]\n",
      "  [4 5 6]\n",
      "  [7 8 9]]]\n"
     ]
    }
   ],
   "source": [
    "array = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
    "print(array)\n",
    "array1 = array[np.newaxis]\n",
    "print(array1)\n",
    "print(np.array([array]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MNIST_convnet_extract.model\n",
    "# model.set_weights()\n",
    "extractor = tf.keras.Model(inputs=model.inputs,outputs=[layer.output for layer in model.layers])\n",
    "\n",
    "features = extractor(np.zeros((1,28,28,1))+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(1, 26, 26, 32), dtype=float32, numpy=\n",
       " array([[[[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 13, 13, 32), dtype=float32, numpy=\n",
       " array([[[[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]],\n",
       " \n",
       "         [[9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          ...,\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.],\n",
       "          [9., 9., 9., ..., 9., 9., 9.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 11, 11, 64), dtype=float32, numpy=\n",
       " array([[[[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          ...,\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 5, 5, 64), dtype=float32, numpy=\n",
       " array([[[[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]],\n",
       " \n",
       "         [[2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.],\n",
       "          [2592., 2592., 2592., ..., 2592., 2592., 2592.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1600), dtype=float32, numpy=array([[2592., 2592., 2592., ..., 2592., 2592., 2592.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 1600), dtype=float32, numpy=array([[2592., 2592., 2592., ..., 2592., 2592., 2592.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 10), dtype=float32, numpy=array([[0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]], dtype=float32)>]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1600, 10), (10,))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_weights()[4].shape,model.get_weights()[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [np.zeros((3,3,1,32))+1,np.zeros((32,)),np.zeros((3,3,32,64))+1,np.zeros((64,)),np.zeros((1600,10))+1,np.zeros((10,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8020/335273382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model.get_weights()[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 28, 28, 1)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18328/2940907349.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "1+None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "101a6ff7ecee390d2e1890350f9112fbc4081685c615de8bd7d4ce8ede852617"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
